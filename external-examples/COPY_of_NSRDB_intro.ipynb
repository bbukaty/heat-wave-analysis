{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NREL National Solar Radiation Database (NSRDB) - HSDS Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates basic usage of the National Renewable Energy Laboratory (NREL) National Solar Radiation Database (NSRDB) data. The data is provided from Amazon Web Services using the HDF Group's Highly Scalable Data Service (HSDS).\n",
    "\n",
    "For this to work you must first install h5pyd:\n",
    "\n",
    "```\n",
    "pip install --user h5pyd\n",
    "```\n",
    "\n",
    "Next you'll need to configure HSDS:\n",
    "\n",
    "```\n",
    "hsconfigure\n",
    "```\n",
    "\n",
    "and enter at the prompt:\n",
    "\n",
    "```\n",
    "hs_endpoint = https://developer.nrel.gov/api/hsds\n",
    "hs_username = None\n",
    "hs_password = None\n",
    "hs_api_key = 3K3JQbjZmWctY0xmIfSYvYgtIcM3CN0cb1Y2w9bf\n",
    "```\n",
    "\n",
    "*The example API key here is for demonstation and is rate-limited per IP. To get your own API key, visit https://developer.nrel.gov/signup/*\n",
    "\n",
    "You can also add the above contents to a configuration file at ~/.hscfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:48:39.175801Z",
     "start_time": "2019-02-06T19:48:39.034304Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import h5pyd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "The NSRDB is provided in annual .h5 files and currently spans 1998-2018.  \n",
    "Each year can be accessed from /nrel/nsrdb/nsrdb_${year}.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:32:02.178393Z",
     "start_time": "2019-02-06T18:32:01.822243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Open the desired year of nsrdb data\n",
    "# server endpoint, username, password is found via a config file\n",
    "f = h5pyd.File(\"/nrel/nsrdb/v3/nsrdb_2012.h5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:32:04.318312Z",
     "start_time": "2019-02-06T18:32:03.824155Z"
    }
   },
   "outputs": [],
   "source": [
    "list(f.attrs)  # list attributes belonging to the root group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:32:09.277364Z",
     "start_time": "2019-02-06T18:32:09.032427Z"
    }
   },
   "outputs": [],
   "source": [
    "f.attrs['Version']   # attributes can be used to provide desriptions of the content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:33:57.735172Z",
     "start_time": "2019-02-06T18:33:57.373693Z"
    }
   },
   "outputs": [],
   "source": [
    "list(f)  # list the datasets in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:34:32.751989Z",
     "start_time": "2019-02-06T18:34:32.630250Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datasets are stored in a 2d array of time x location\n",
    "dset = f['ghi']\n",
    "dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:45:17.972025Z",
     "start_time": "2019-02-06T18:45:17.286944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract datetime index for datasets\n",
    "time_index = pd.to_datetime(f['time_index'][...].astype(str))\n",
    "time_index # Temporal resolution is 30min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:46:51.882658Z",
     "start_time": "2019-02-06T18:46:06.078162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Locational information is stored in either 'meta' or 'coordinates'\n",
    "meta = pd.DataFrame(f['meta'][...])\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:47:46.899747Z",
     "start_time": "2019-02-06T18:47:46.896662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datasets have been saved as integers\n",
    "dset.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:47:51.066179Z",
     "start_time": "2019-02-06T18:47:51.062426Z"
    }
   },
   "outputs": [],
   "source": [
    "dset.shape[0] * dset.shape[1] * 2 * 10**-9 # 70 GB per dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:47:57.377851Z",
     "start_time": "2019-02-06T18:47:57.374273Z"
    }
   },
   "outputs": [],
   "source": [
    "dset.chunks # Chunked by week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:47:58.010112Z",
     "start_time": "2019-02-06T18:47:58.005677Z"
    }
   },
   "outputs": [],
   "source": [
    "dset.chunks[0] * dset.chunks[1] * 2 * 10**-6 # 2 MB per chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:49:17.786073Z",
     "start_time": "2019-02-06T18:49:17.671184Z"
    }
   },
   "outputs": [],
   "source": [
    "# To convert dataset values back to floats use the 'psm_scale_factor'\n",
    "dset.attrs['psm_scale_factor'] # Irradiance values have been truncated to integer precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:52:13.089310Z",
     "start_time": "2019-02-06T18:52:12.342907Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: this part of the example notebook wasn't working so I commented it out. --buck.\n",
    "\n",
    "# # wind speed on the other hand has single decimal percision when scaled by 10\n",
    "# scale_factor = f['wind_speed'].attrs['psm_scale_factor']\n",
    "# units = f['wind_speed'].attrs['psm_units']\n",
    "# print('wind_speed scale factor = ', scale_factor)\n",
    "# print('wind_speed units after unscaling = ', units)\n",
    "# f['wind_speed'][0, 0] / scale_factor # divide by scale_factor to return native value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the time_index from the server and convert to a pandas DatetimeIndex for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:57:48.925869Z",
     "start_time": "2019-02-06T18:57:47.990623Z"
    }
   },
   "outputs": [],
   "source": [
    "time_index = pd.to_datetime(f['time_index'][...].astype(str))\n",
    "time_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract indexes for a particular span of time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:00:14.646068Z",
     "start_time": "2019-02-06T19:00:14.641059Z"
    }
   },
   "outputs": [],
   "source": [
    "march = time_index.month == 3\n",
    "np.where(march)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a particular date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:16:18.978254Z",
     "start_time": "2019-02-06T19:16:18.973874Z"
    }
   },
   "outputs": [],
   "source": [
    "timestep = np.where(time_index == '2012-07-04 00:00:00')[0][0]\n",
    "timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:16:28.086246Z",
     "start_time": "2019-02-06T19:16:24.814153Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract coordinates (lat, lon)\n",
    "print(dict(f['coordinates'].attrs))\n",
    "coords = f['coordinates'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:30:40.930339Z",
     "start_time": "2019-02-06T19:30:37.902430Z"
    }
   },
   "outputs": [],
   "source": [
    "dset = f['ghi']\n",
    "data = dset[timestep, ::100]   # extract every 10th location at a particular time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() # Combine data with coordinates in a DataFrame\n",
    "df['longitude'] = coords[::100, 1]\n",
    "df['latitude'] = coords[::100, 0]\n",
    "df['ghi'] = data / dset.attrs['psm_scale_factor'] # unscale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:30:40.935891Z",
     "start_time": "2019-02-06T19:30:40.932229Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:30:50.703645Z",
     "start_time": "2019-02-06T19:30:44.870411Z"
    }
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x='longitude', y='latitude', c='ghi',\n",
    "                colormap='YlOrRd',\n",
    "                title=str(time_index[timestep]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:38:03.467178Z",
     "start_time": "2019-02-06T19:38:03.343285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Full resolution subset of Colorado\n",
    "meta = pd.DataFrame(f['meta'][...])\n",
    "CA = meta.loc[meta['state'] == b'California'] # Note .h5 saves strings as bit-strings\n",
    "CA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:38:14.050394Z",
     "start_time": "2019-02-06T19:38:09.966272Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dset[timestep][CA.index]  # full-resolution subset\n",
    "df = CA[['longitude', 'latitude']].copy()\n",
    "df['ghi'] = data / dset.attrs['psm_scale_factor']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:38:16.260753Z",
     "start_time": "2019-02-06T19:38:15.367784Z"
    }
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x='longitude', y='latitude', c='ghi',\n",
    "                colormap='YlOrRd',\n",
    "                title=str(time_index[timestep]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Timeseries for given Lat/Lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:52:44.346725Z",
     "start_time": "2019-02-06T19:52:34.038821Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unlike the gridded WTK data the NSRDB is provided as sparse time-series dataset.\n",
    "# The quickest way to find the nearest site it using a KDtree\n",
    "\n",
    "dset_coords = f['coordinates'][...]\n",
    "tree = cKDTree(dset_coords)\n",
    "def nearest_site(tree, lat_coord, lon_coord):\n",
    "    lat_lon = np.array([lat_coord, lon_coord])\n",
    "    dist, pos = tree.query(lat_lon)\n",
    "    return pos\n",
    "\n",
    "NewYorkCity = (40.7128, -74.0059)\n",
    "NewYorkCity_idx = nearest_site(tree, NewYorkCity[0], NewYorkCity[1] )\n",
    "\n",
    "print(\"Site index for New York City: \\t\\t {}\".format(NewYorkCity_idx))\n",
    "print(\"Coordinates of New York City: \\t {}\".format(NewYorkCity))\n",
    "print(\"Coordinates of nearest point: \\t {}\".format(dset_coords[NewYorkCity_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:53:48.160502Z",
     "start_time": "2019-02-06T19:53:46.607119Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the entire 2012 timeseries data for a point in NYC\n",
    "%time tseries = dset[:, NewYorkCity_idx] / dset.attrs['psm_scale_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:53:48.165562Z",
     "start_time": "2019-02-06T19:53:48.162324Z"
    }
   },
   "outputs": [],
   "source": [
    "len(tseries)   # 1 years * 365 days * 24 hours * 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:54:20.235635Z",
     "start_time": "2019-02-06T19:54:20.063966Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(time_index, tseries)\n",
    "plt.ylabel(\"ghi\")\n",
    "plt.title(\"NYC ghi in 2012\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GHI Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:58:14.770799Z",
     "start_time": "2019-02-06T19:58:14.726103Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ghi': tseries}, index=time_index)\n",
    "df[\"year\"] = df.index.year\n",
    "df[\"month\"] = df.index.month\n",
    "df[\"day\"] = df.index.day\n",
    "df[\"hour\"] = df.index.hour\n",
    "\n",
    "agg = df.groupby([\"month\",\"hour\"]).mean()\n",
    "agg = agg.reset_index().pivot(index=\"month\",columns=\"hour\",values=\"ghi\")\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:58:30.404312Z",
     "start_time": "2019-02-06T19:58:30.214762Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(agg)\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Month\")\n",
    "plt.title(\"12 x 24 Mean GHI (W/m^2)\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
